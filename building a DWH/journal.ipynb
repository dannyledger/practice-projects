{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e338f517",
   "metadata": {},
   "source": [
    "### **Step 1** | Scoping out the project\n",
    "\n",
    "---\n",
    "\n",
    "#### Objective\n",
    "\n",
    "Develop a modern data warehouse using SQL Server to consolidate sales data, enabling analytical reporting and informed decision-making.\n",
    "\n",
    "#### Specifications\n",
    "\n",
    "- **Data Sources**: Import data from two source systems (ERP and CRM) provided as CSV files.\n",
    "- **Data Quality**: Cleanse and resolve data quality issues prior to analysis.\n",
    "- **Integration**: Combine both sources into a single, user-friendly data model designed for analytical queries.\n",
    "- **Scope**: Focus on the latest dataset only; historization of data is not required.\n",
    "- **Documentation**: Provide clear documentation of the data model to support both business stakeholders and analytics teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85f446",
   "metadata": {},
   "source": [
    "#### Medallion Architecture\n",
    "\n",
    "As per the course’s recommendation, we will be using the Medallion data management paradigm. This layered approach is particularly effective for building a modern data warehouse because it separates raw, cleansed, and curated datasets into clear stages—commonly referred to as Bronze, Silver, and Gold layers. By structuring the pipeline this way, we ensure that each layer has a distinct purpose: Bronze holds unaltered, raw source data; Silver refines and cleanses this data for reliability; and Gold aggregates it into business-ready tables optimised for reporting and analytics.\n",
    "\n",
    "Opting for Medallion provides several advantages. It improves data quality and trust by ensuring transformations are traceable and reproducible, as all data first lands in a raw state before being standardised and validated. It also enhances maintainability and scalability, allowing us to debug issues at the appropriate layer rather than across the entire warehouse. \n",
    "\n",
    "<br>\n",
    "\n",
    "![data architecture figure 1 image](assets/img/journal_fig1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "| | Bronze Layer | Silver Layer | Gold Layer |\n",
    "| - | - | - | - |\n",
    "| **Definition** | Raw, unprocessed data as-is from sources | Clean and standardised data | Business-ready data | \n",
    "| **Objective** | Traceability & debugging | (Intermediate layer) Prepare data for analysis | Provide data to be consumed for reporting & analytics |\n",
    "| **Object Type** | Tables | Tables | Views |\n",
    "| **Load Method** | Full load (truncate & insert) | Full load (truncate & insert) | None |\n",
    "| **Data Transformation** | None (as-is) | Data cleaning, standardisation, normalisation, enrichment & derived columns | Data integration, aggregation, business logic & rules |\n",
    "| **Data Modeling** | None (as-is) | None (as-is) | Start schema, aggregated objects, flat tables |\n",
    "| **Target Audience** | Data engineers | Data engineers & analysts | Data analysts & business users |  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4775880",
   "metadata": {},
   "source": [
    "#### Layers for Separation of Concerns (SoC)\n",
    "\n",
    "The above layers mean that we have separation of concerns (SoC) - an important principle where we take a complex system and break it down into independent parts, each focused on a specific responsibility or operation without overlapping with others. So for a data warehouse, SoC means breaking the architecture into independent layers—such as ingestion, transformation, storage, and consumption—so each layer handles its own responsibility without interfering with the others...\n",
    "\n",
    "<br>\n",
    "\n",
    "![data architecture figure 2 image](assets/img/journal_fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1573535",
   "metadata": {},
   "source": [
    "#### Beginnings...\n",
    "\n",
    "Moving forward, this journal will document each stage of the data warehouse build with clear, structured notes. We will capture:\n",
    "\n",
    "1. **Data Source Overview** – Key details about each source, including its format, refresh frequency, volume, and method of access.\n",
    "2. **Data Quality and Validation** – How we identify and resolve issues such as missing data, duplicates, and inconsistencies, as well as checks between Bronze and Silver layers.\n",
    "3. **Medallion Layer Objectives** – The purpose and responsibilities of the Bronze, Silver, and Gold layers, along with how each supports data trust and reporting readiness.\n",
    "4. **Target Schema Design** – Sketches and notes on fact and dimension tables, including any decisions around star vs. snowflake schema design.\n",
    "5. **ETL / ELT Flow** – Steps for moving data between layers, whether through incremental or full loads, and how the process will be orchestrated.\n",
    "6. **Testing and Monitoring** – Plans for data validation, quality checks, and ongoing monitoring to ensure the reliability of the Gold outputs.\n",
    "7. **Versioning and Progress Log** – A running journal of decisions, challenges, lessons learned, and key milestones as the project evolves.\n",
    "\n",
    "#### The high-level goal\n",
    "\n",
    "![data architecture figure 3 image](assets/img/journal_fig3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf77ee",
   "metadata": {},
   "source": [
    "### **Step 2** | Establishing rules & naming conventions\n",
    "\n",
    "---\n",
    "\n",
    "#### Naming Conventions\n",
    "\n",
    "We need naming conventions to keep our data systems clear, consistent, and scalable. They let us understand datasets and pipelines at a glance, reduce errors, and make automation with tools like Airflow or dbt much easier. Consistent names help us collaborate better, onboard new team members faster, and simplify governance tasks like lineage and documentation. With predictable patterns in place, our Medallion or multi-source warehouse can grow without becoming messy or confusing.\n",
    "\n",
    "#### General Principles\n",
    "- **Naming Conventions**: Use snake_case, with lowercase letters and underscores (_) to separate words.\n",
    "- **Language**: Use English for all names.\n",
    "- **Avoid Reserved Words**: Do not use SQL reserved words as object names.\n",
    "\n",
    "#### Table Naming Conventions\n",
    "\n",
    "**Bronze Layer Rules**\n",
    "\n",
    "All names must start with the source system name, and table names must match their original names without renaming.\n",
    "- `[sourcesystem_entity]`\n",
    "    - `[sourcesystem]`: Name of the source system (e.g., crm, erp).\n",
    "    - `[entity]`: Exact table name from the source system.\n",
    "    - Example: `crm_customer_info` → Customer information from the CRM system.\n",
    "\n",
    "**Silver Layer Rules**\n",
    "\n",
    "In this scenario, we are not renaming items between Bronze and Silver. So the rules above will apply in Silver. \n",
    "\n",
    "**Gold Layer Rules**\n",
    "\n",
    "All names must use meaningful, business-aligned names for tables, starting with the category prefix.\n",
    "- `[category_entity]`\n",
    "    - `[category]`: Describes the role of the table, such as dim (dimension) or fact (fact table).\n",
    "    - `[entity]`: Descriptive name of the table, aligned with the business domain (e.g., customers, products, sales).\n",
    "    - Examples:\n",
    "        - `dim_customers` → Dimension table for customer data.\n",
    "        - `fact_sales` → Fact table containing sales transactions.\n",
    "\n",
    "**Glossary of Category Patterns**\n",
    "| Pattern | Meaning | Example(s) |\n",
    "| - | - | - |\n",
    "| `dim_` | Dimension table | `dim_customer`, `dim_product` | \n",
    "| `fact_` | Fact table | `fact_sales` | \n",
    "| `agg_` | Aggregated table | `agg_customer`, `agg_sales_monthly` | \n",
    "\n",
    "\n",
    "#### Column Naming Conventions\n",
    "\n",
    "**Surrogate Keys**\n",
    "\n",
    "- All primary keys in dimension tables must use the suffix `_key`.\n",
    "- `[table_name]_key`\n",
    "    - [table_name]: Refers to the name of the table or entity the key belongs to.\n",
    "    - `_key`: A suffix indicating that this column is a surrogate key.\n",
    "    - Example: `customer_key` → Surrogate key in the dim_customers table.\n",
    "\n",
    "**Technical Columns**\n",
    "\n",
    "- All technical columns must start with the prefix dwh_, followed by a descriptive name indicating the column's purpose.\n",
    "- `dwh_[column_name]`\n",
    "    - `dwh`: Prefix exclusively for system-generated metadata.\n",
    "    - `[column_name]`: Descriptive name indicating the column's purpose.\n",
    "    - Example: `dwh_load_date` → System-generated column used to store the date when the record was loaded.\n",
    "\n",
    "**Stored Procedure**\n",
    "\n",
    "All stored procedures used for loading data must follow the naming pattern: \n",
    "- `load_[layer]`.\n",
    "    - `[layer]`: Represents the layer being loaded, such as bronze, silver, or gold.\n",
    "    - Example:\n",
    "        - `load_bronze` → Stored procedure for loading data into the Bronze layer.\n",
    "        - `load_silver` → Stored procedure for loading data into the Silver layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fe172",
   "metadata": {},
   "source": [
    "### **Step 3** | Ready the database & schema\n",
    "\n",
    "---\n",
    "\n",
    "To begin capturing our design into code - we need to create and select a database, followed by establishing the schemas (which reflect our layers).\n",
    "\n",
    "A key rule to note with any shared scripts - particularly high-level ones (see below), is to include a clear description for each, as well as warnings regarding its purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7b8fe",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "/*\n",
    "=============================================================\n",
    "Create Database and Schemas\n",
    "=============================================================\n",
    "Script Purpose:\n",
    "    This script creates a new database named 'DataWarehouse' after checking if it already exists. \n",
    "    If the database exists, it is dropped and recreated. Additionally, the script sets up three schemas \n",
    "    within the database: 'bronze', 'silver', and 'gold'.\n",
    "\t\n",
    "W A R N I N G :\n",
    "    Running this script will drop the entire 'DataWarehouse' database if it exists. \n",
    "    All data in the database will be permanently deleted. Proceed with caution \n",
    "    and ensure you have proper backups before running this script.\n",
    "*/\n",
    "\n",
    "USE master;\n",
    "GO\n",
    "\n",
    "-- Drop and recreate the 'DataWarehouse' database\n",
    "IF EXISTS (SELECT 1 FROM sys.databases WHERE name = 'DataWarehouse')\n",
    "BEGIN\n",
    "    ALTER DATABASE DataWarehouse SET SINGLE_USER WITH ROLLBACK IMMEDIATE;\n",
    "    DROP DATABASE DataWarehouse;\n",
    "END;\n",
    "GO\n",
    "\n",
    "-- create the DWH database\n",
    "CREATE DATABASE DateWarehouse;\n",
    "GO\n",
    "\n",
    "USE DateWarehouse;\n",
    "GO\n",
    "\n",
    "-- create schemas \n",
    "CREATE SCHEMA bronze;\n",
    "GO\n",
    "\n",
    "CREATE SCHEMA silver;\n",
    "GO\n",
    "\n",
    "CREATE SCHEMA gold;\n",
    "GO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd114b",
   "metadata": {},
   "source": [
    "### **Step 4** | Developing the Bronze Layer\n",
    "\n",
    "---\n",
    "\n",
    "For us to begin building the first layer of our warehouse's architecture, we like any discipline, need to carefully **understand the sources** and the context surrounding them. We need to meet with stakeholders, and gauge:\n",
    "\n",
    "**Business Context & Ownership**\n",
    "- Who owns the data?\n",
    "- What business process it supports?\n",
    "- Systems and data documentation\n",
    "- Data model and data catalog \n",
    "\n",
    "**Architecture & Technology Stack**\n",
    "- How is data stored? \n",
    "- What are the integration capabilities?\n",
    "\n",
    "**Extract & Load**\n",
    "- Incremental vs. full load?\n",
    "- Data scope & historical needs\n",
    "- What is the expected size of the extracts?\n",
    "- Are there any data volume limitations?\n",
    "- How to avoid impacting the source system's performance?\n",
    "- Authentication and authorisation \n",
    "\n",
    "#### Specification of the Bronze Layer\n",
    "\n",
    "The Bronze Layer will handle raw, un-processed data as-is from sources. The overall objective of this layer is traceability and debugging.\n",
    "\n",
    "We are doing a full-load (truncate and insert), producing tables.\n",
    "\n",
    "To get started, we will explore the data to identify the column names and data types (ie. **Data Profiling**)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "376fffbe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "cst_id,cst_key,cst_firstname,cst_lastname,cst_marital_status,cst_gndr,cst_create_date\n",
    "11000,AW00011000, Jon,Yang ,M,M,2025-10-06\n",
    "11001,AW00011001,Eugene,Huang  ,S,M,2025-10-06\n",
    "11002,AW00011002,Ruben, Torres,M,M,2025-10-06\n",
    "11003,AW00011003,Christy,  Zhu,S,F,2025-10-06\n",
    "11004,AW00011004, Elizabeth,Johnson,S,F,2025-10-06\n",
    "11005,AW00011005,Julio,Ruiz,S,M,2025-10-06\n",
    "11006,AW00011006,Janet,Alvarez,S,F,2025-10-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a610beb5",
   "metadata": {},
   "source": [
    "_previewing 8 of 15000+ lines_\n",
    "\n",
    "Referencing the data source above, and the naming conventions we set for each layer, we create our DDL (Data Definition Language). We repeat this process for each table to a total of six. These will store the raw data from the two sources folders (each holding three CSV files respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6686f46",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE bronze.crm_prd_info (\n",
    "    prd_id INT,\n",
    "    prd_key NVARCHAR(50),\n",
    "    prd_nm NVARCHAR(50),\n",
    "    prd_cost INT,\n",
    "    prd_line NVARCHAR(2),\n",
    "    prd_start_dt DATE,\n",
    "    prd_end_dt DATE\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23eb0a",
   "metadata": {},
   "source": [
    "Once complete, we have six tables in the Bronze layer schema, of which all clearly reference their source system. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fc81d9b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "└── Bronze Layer/                        # schema           \n",
    "    ├── bronze.crm_cust_info/            # table for CRM \n",
    "    ├── bronze.crm_prd_info/\n",
    "    ├── bronze.crm_sales_details/        \n",
    "    ├── bronze.erp_cust_az12/            # table for ERP   \n",
    "    ├── bronze.erp_loc_a101/        \n",
    "    └── bronze.erp_px_cat_gtv2/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
