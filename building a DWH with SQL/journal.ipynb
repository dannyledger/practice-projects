{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e338f517",
   "metadata": {},
   "source": [
    "### **3rd August** | Scoping out the project\n",
    "\n",
    "---\n",
    "\n",
    "#### Objective\n",
    "\n",
    "Develop a modern data warehouse using SQL Server to consolidate sales data, enabling analytical reporting and informed decision-making.\n",
    "\n",
    "#### Specifications\n",
    "\n",
    "- **Data Sources**: Import data from two source systems (ERP and CRM) provided as CSV files.\n",
    "- **Data Quality**: Cleanse and resolve data quality issues prior to analysis.\n",
    "- **Integration**: Combine both sources into a single, user-friendly data model designed for analytical queries.\n",
    "- **Scope**: Focus on the latest dataset only; historization of data is not required.\n",
    "- **Documentation**: Provide clear documentation of the data model to support both business stakeholders and analytics teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85f446",
   "metadata": {},
   "source": [
    "#### Medallion Architecture\n",
    "\n",
    "As per the course’s recommendation, we will be using the Medallion data management paradigm. This layered approach is particularly effective for building a modern data warehouse because it separates raw, cleansed, and curated datasets into clear stages—commonly referred to as Bronze, Silver, and Gold layers. By structuring the pipeline this way, we ensure that each layer has a distinct purpose: Bronze holds unaltered, raw source data; Silver refines and cleanses this data for reliability; and Gold aggregates it into business-ready tables optimised for reporting and analytics.\n",
    "\n",
    "Opting for Medallion provides several advantages. It improves data quality and trust by ensuring transformations are traceable and reproducible, as all data first lands in a raw state before being standardised and validated. It also enhances maintainability and scalability, allowing us to debug issues at the appropriate layer rather than across the entire warehouse. \n",
    "\n",
    "<br>\n",
    "\n",
    "![data architecture figure 1 image](img/journal_fig1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "| | Bronze Layer | Silver Layer | Gold Layer |\n",
    "| - | - | - | - |\n",
    "| **Definition** | Raw, unprocessed data as-is from sources | Clean and standardised data | Business-ready data | \n",
    "| **Objective** | Traceability & debugging | (Intermediate layer) Prepare data for analysis | Provide data to be consumed for reporting & analytics |\n",
    "| **Object Type** | Tables | Tables | Views |\n",
    "| **Load Method** | Full load (truncate & insert) | Full load (truncate & insert) | None |\n",
    "| **Data Transformation** | None (as-is) | Data cleaning, standardisation, normalisation, enrichment & derived columns | Data integration, aggregation, business logic & rules |\n",
    "| **Data Modeling** | None (as-is) | None (as-is) | Start schema, aggregated objects, flat tables |\n",
    "| **Target Audience** | Data engineers | Data engineers & analysts | Data analysts & business users |  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4775880",
   "metadata": {},
   "source": [
    "#### Layers for Separation of Concerns (SoC)\n",
    "\n",
    "The above layers mean that we have separation of concerns (SoC) - an important principle where we take a complex system and break it down into independent parts, each focused on a specific responsibility or operation without overlapping with others. So for a data warehouse, SoC means breaking the architecture into independent layers—such as ingestion, transformation, storage, and consumption—so each layer handles its own responsibility without interfering with the others...\n",
    "\n",
    "<br>\n",
    "\n",
    "![data architecture figure 2 image](img/journal_fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1573535",
   "metadata": {},
   "source": [
    "#### Beginnings...\n",
    "\n",
    "Moving forward, this journal will document each stage of the data warehouse build with clear, structured notes. We will capture:\n",
    "\n",
    "1. **Data Source Overview** – Key details about each source, including its format, refresh frequency, volume, and method of access.\n",
    "2. **Data Quality and Validation** – How we identify and resolve issues such as missing data, duplicates, and inconsistencies, as well as checks between Bronze and Silver layers.\n",
    "3. **Medallion Layer Objectives** – The purpose and responsibilities of the Bronze, Silver, and Gold layers, along with how each supports data trust and reporting readiness.\n",
    "4. **Target Schema Design** – Sketches and notes on fact and dimension tables, including any decisions around star vs. snowflake schema design.\n",
    "5. **ETL / ELT Flow** – Steps for moving data between layers, whether through incremental or full loads, and how the process will be orchestrated.\n",
    "6. **Testing and Monitoring** – Plans for data validation, quality checks, and ongoing monitoring to ensure the reliability of the Gold outputs.\n",
    "7. **Versioning and Progress Log** – A running journal of decisions, challenges, lessons learned, and key milestones as the project evolves.\n",
    "\n",
    "#### The high-level goal\n",
    "\n",
    "![data architecture figure 3 image](img/journal_fig3.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
